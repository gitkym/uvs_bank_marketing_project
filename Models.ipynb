{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import time as time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the data --> (41188, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "data = path + '/dataset/bank/bank-additional/bank-additional-full.csv'\n",
    "df_orig = pd.read_csv(data, sep=';')\n",
    "print(f'size of the data --> {df_orig.shape}')\n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates dropped --> 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>NA_count</th>\n",
       "      <th>unique_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>housing</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loan</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>contact</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>month</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>duration</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>campaign</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pdays</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>previous</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cons.price.idx</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>euribor3m</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nr.employed</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>y</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            column    dtype NA_count unique_count\n",
       "0              age    int64        0           78\n",
       "1              job   object        0           12\n",
       "2          marital   object        0            4\n",
       "3        education   object        0            8\n",
       "4          default   object        0            3\n",
       "5          housing   object        0            3\n",
       "6             loan   object        0            3\n",
       "7          contact   object        0            2\n",
       "8            month   object        0           10\n",
       "9      day_of_week   object        0            5\n",
       "10        duration    int64        0         1544\n",
       "11        campaign    int64        0           42\n",
       "12           pdays    int64        0           27\n",
       "13        previous    int64        0            8\n",
       "14        poutcome   object        0            3\n",
       "15    emp.var.rate  float64        0           10\n",
       "16  cons.price.idx  float64        0           26\n",
       "17   cons.conf.idx  float64        0           26\n",
       "18       euribor3m  float64        0          316\n",
       "19     nr.employed  float64        0           11\n",
       "20               y   object        0            2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table listing column types etc\n",
    "df = df_orig.copy()        # make a copy of the data before any transformations\n",
    "\n",
    "df_info = pd.DataFrame([df.columns,df.dtypes, df.isna().sum(), df.nunique()])\n",
    "df_info = df_info.T\n",
    "df_info.columns = ['column','dtype','NA_count', 'unique_count']\n",
    "print(f'Duplicates dropped --> {df.duplicated().sum()}')\n",
    "# drop duplicates, 12 rows\n",
    "df = df.drop_duplicates()\n",
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pipeline for preprocessing'''\n",
    "# Drop response variable from the dataframe\n",
    "y = df['y']\n",
    "df = df.drop('y', axis=1)\n",
    "# drop duration as it is not known before a call is performed\n",
    "df.drop('duration', axis=1)\n",
    "\n",
    "# Create a pipeline for categorical features\n",
    "cat_features = df.select_dtypes(include=['object']).columns\n",
    "cat_pipeline = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "# df_cat= cat_pipeline.fit_transform(df[cat_features])\n",
    "\n",
    "# Create a pipeline for numerical features\n",
    "num_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('cat', cat_pipeline, cat_features),\n",
    "        ('num', num_pipeline, num_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9059009227780476\n"
     ]
    }
   ],
   "source": [
    "'''Linear Regression'''\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "clf = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "# Get the accuracy score\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "parameters = {\n",
    "    'classifier__penalty' : ['l2', 'none'], \n",
    "    'classifier__C'       : np.logspace(-3,3,5),\n",
    "    'classifier__solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}\n",
      "Accuracy : 0.912446873102611\n",
      "Training Time : 87.57204914093018\n",
      "Test Accuracy : 0.9061437591063624\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# clf_grid = GridSearchCV(clf,                    # model\n",
    "#                    param_grid = parameters,   # hyperparameters\n",
    "#                    scoring='accuracy',        # metric for scoring\n",
    "#                    cv=cv)                     # number of folds\n",
    "\n",
    "# start_time = time.time()\n",
    "# clf_grid.fit(X_train,y_train)\n",
    "# print(\"Tuned Hyperparameters :\", clf_grid.best_params_)\n",
    "# print(\"Accuracy :\",clf_grid.best_score_)\n",
    "# print('Training Time :', time.time() - start_time)\n",
    "# print(\"Test Accuracy :\",clf_grid.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_param = pd.DataFrame(clf_grid.cv_results_)\n",
    "# df_param[['param_classifier__C','param_classifier__penalty','param_classifier__solver','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'preprocessor', 'classifier', 'preprocessor__n_jobs', 'preprocessor__remainder', 'preprocessor__sparse_threshold', 'preprocessor__transformer_weights', 'preprocessor__transformers', 'preprocessor__verbose', 'preprocessor__verbose_feature_names_out', 'preprocessor__cat', 'preprocessor__num', 'preprocessor__cat__memory', 'preprocessor__cat__steps', 'preprocessor__cat__verbose', 'preprocessor__cat__onehot', 'preprocessor__cat__onehot__categories', 'preprocessor__cat__onehot__drop', 'preprocessor__cat__onehot__dtype', 'preprocessor__cat__onehot__handle_unknown', 'preprocessor__cat__onehot__sparse', 'preprocessor__num__memory', 'preprocessor__num__steps', 'preprocessor__num__verbose', 'preprocessor__num__std_scaler', 'preprocessor__num__std_scaler__copy', 'preprocessor__num__std_scaler__with_mean', 'preprocessor__num__std_scaler__with_std', 'classifier__C', 'classifier__class_weight', 'classifier__dual', 'classifier__fit_intercept', 'classifier__intercept_scaling', 'classifier__l1_ratio', 'classifier__max_iter', 'classifier__multi_class', 'classifier__n_jobs', 'classifier__penalty', 'classifier__random_state', 'classifier__solver', 'classifier__tol', 'classifier__verbose', 'classifier__warm_start'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(X_train, y_train, X_test, y_test, model, param_grid, folds=5, scoring = 'roc_auc'):\n",
    "    '''Function to fit a model and return the best parameters and accuracy score'''\n",
    "    # # Create a pipeline for categorical features\n",
    "    # cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "    # cat_pipeline = Pipeline([\n",
    "    #         ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    # ])\n",
    "\n",
    "    # # Create a pipeline for numerical features\n",
    "    # num_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    # num_pipeline = Pipeline([\n",
    "    #     ('std_scaler', StandardScaler())\n",
    "    # ])\n",
    "\n",
    "    # # Create a column transformer\n",
    "    # preprocessor = ColumnTransformer([\n",
    "    #         ('cat', cat_pipeline, cat_features),\n",
    "    #         ('num', num_pipeline, num_features)\n",
    "    # ])\n",
    "    \n",
    "    # Create a pipeline for the model\n",
    "    clf = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Create a grid search object\n",
    "    cv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    clf_grid = GridSearchCV(clf,                    # model\n",
    "                       param_grid = param_grid,   # hyperparameters\n",
    "                       scoring=scoring,        # metric for scoring\n",
    "                       cv=cv)                     # number of folds\n",
    "    \n",
    "    # Fit the model\n",
    "    start_time = time.time()\n",
    "    clf_grid.fit(X_train,y_train)\n",
    "    print(\"Tuned Hyperparameters :\", clf_grid.best_params_)\n",
    "    print(\"Accuracy :\",clf_grid.best_score_)\n",
    "    # print training time in minutes\n",
    "    print('Training Time : {} minutes'.format(round((time.time() - start_time)/60,3)))\n",
    "    print(\"Test Score :\",clf_grid.score(X_test,y_test))\n",
    "    \n",
    "    # Get the results\n",
    "    df_param = pd.DataFrame(clf_grid.cv_results_)\n",
    "    \n",
    "    return clf_grid, df_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make parameter grids\n",
    "param_lr = {\n",
    "    'classifier__penalty' : ['l2', 'none'], \n",
    "    'classifier__C'       : np.logspace(-5,5,5),\n",
    "    'classifier__solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "param_svm = {\n",
    "    'classifier__C'       : [0.1, 1, 10, 100],\n",
    "    'classifier__kernel'  : ['linear', 'rbf', 'sigmoid'],\n",
    "    'classifier__gamma'   : ['auto'],\n",
    "}\n",
    "param_rf = {\n",
    "    'classifier__n_estimators' : [100, 200, 300],\n",
    "    'classifier__max_depth'    : [10, 20, 30],\n",
    "    'classifier__min_samples_split' : [2, 5, 10],\n",
    "    'classifier__min_samples_leaf'  : [1, 2],\n",
    "}\n",
    "param_dt = {\n",
    "    'classifier__max_depth' : [5, 10, 15, 20, 25],\n",
    "    'classifier__min_samples_split' : [2, 5, 10, 15, 100],\n",
    "    'classifier__min_samples_leaf'  : [1, 2, 5, 10, 15],\n",
    "}\n",
    "param_sgd = {\n",
    "    'classifier__loss' : ['hinge', 'log', 'squared_hinge'],\n",
    "    'classifier__penalty' : ['l2', 'l1', 'elasticnet', 'none'],\n",
    "    'classifier__alpha' : [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    # 'classifier__max_iter' : [1000, 2000, 3000, 4000, 5000],\n",
    "    # 'classifier__tol' : [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'classifier__learning_rate' : ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    # 'classifier__eta0' : [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "}\n",
    "param_knn = {\n",
    "    'classifier__n_neighbors' : [3, 5, 7],\n",
    "    'classifier__weights' : ['uniform', 'distance'],\n",
    "    'classifier__algorithm' : ['auto'],\n",
    "    'classifier__leaf_size' : [10, 20, 30, 40],\n",
    "    'classifier__p' : [2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "folds = 5\n",
    "model = LogisticRegression(random_state=random_state)\n",
    "parameters = param_lr\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=random_state)\n",
    "clf_grid, clf_param = make_model(X_train, y_train, X_test, y_test, model, parameters, folds=folds)\n",
    "\n",
    "# save the model to disk\n",
    "pickle.dump(clf_grid, open(f'model_lr_{folds}.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'classifier__C': 10, 'classifier__degree': 2, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}\n",
      "Accuracy : 0.9121129326047359\n",
      "Training Time : 1271.154 seconds\n",
      "Test Accuracy : 0.907722195240408\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "folds = 5\n",
    "model = SVC(random_state=random_state)\n",
    "parameters = param_svm\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=random_state)\n",
    "clf_grid, clf_param = make_model(X_train, y_train, X_test, y_test, model, parameters, folds=folds)\n",
    "\n",
    "# save the model to disk\n",
    "pickle.dump(clf_grid, open(f'model_svc_{folds}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'classifier__max_depth': 24, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 300}\n",
      "Accuracy : 0.9136915604128719\n",
      "Training Time : 6.149 minutes\n",
      "Test Accuracy : 0.9107576493443419\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "folds = 5\n",
    "model = RandomForestClassifier(random_state=random_state)\n",
    "parameters = param_rf\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=random_state)\n",
    "clf_grid, clf_param = make_model(X_train, y_train, X_test, y_test, model, parameters, folds=folds)\n",
    "\n",
    "\n",
    "pickle.dump(clf_grid, open(f'model_rf_{folds}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 100}\n",
      "Accuracy : 0.9321894989752376\n",
      "Training Time : 1.688 minutes\n",
      "Test Accuracy : 0.9336759132530941\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "folds = 5\n",
    "model = DecisionTreeClassifier(random_state=random_state)\n",
    "parameters = param_dt\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=random_state)\n",
    "clf_grid, clf_param = make_model(X_train, y_train, X_test, y_test, model, parameters, folds=folds)\n",
    "\n",
    "\n",
    "pickle.dump(clf_grid, open(f'model_dt_{folds}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'classifier__alpha': 0.001, 'classifier__learning_rate': 'optimal', 'classifier__loss': 'log', 'classifier__penalty': 'none'}\n",
      "Accuracy : 0.9358794670826871\n",
      "Training Time : 6.103 minutes\n",
      "Test Score : 0.9286337511154521\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "folds = 5\n",
    "model = SGDClassifier(random_state=random_state)\n",
    "parameters = param_sgd\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=random_state)\n",
    "clf_grid, clf_param = make_model(X_train, y_train, X_test, y_test, model, parameters, folds=folds)\n",
    "\n",
    "\n",
    "pickle.dump(clf_grid, open(f'model_sgd_{folds}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'classifier__algorithm': 'auto', 'classifier__leaf_size': 10, 'classifier__n_neighbors': 11, 'classifier__p': 2, 'classifier__weights': 'distance'}\n",
      "Accuracy : 0.9068433578052135\n",
      "Training Time : 40.134 minutes\n",
      "Test Score : 0.9007684658255266\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "folds = 5\n",
    "model = KNeighborsClassifier()\n",
    "parameters = param_knn\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=random_state)\n",
    "clf_grid, clf_param = make_model(X_train, y_train, X_test, y_test, model, parameters, folds=folds)\n",
    "\n",
    "\n",
    "pickle.dump(clf_grid, open(f'model_knn_{folds}.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When to Use Accuracy?\n",
    " \n",
    "\n",
    "Accuracy is used for balanced datasets i.e. when the classes are equally distributed. \n",
    "\n",
    "A real-life example is fraud detection which must correctly identify and distinguish fraudulent transactions (class of interest) from regular transactions. Usually, fraudulent transactions are rare i.e. their occurrence in the training data set would be less than ~1%.\n",
    "\n",
    "Accuracy in this case would be a biased representation of model performance and would declare the model good even if it identifies every transaction as non-fraudulent. Such a model would have high accuracy but fails to predict any fraudulent transaction, defeating the purpose of building the model. \n",
    "\n",
    " \n",
    "\n",
    "When to Use AUC?\n",
    " \n",
    "\n",
    "AUC is well-suited for imbalanced datasets. For example, the fraud detection model must correctly identify fraud even if it comes at the cost of flagging some (a small number) of the non-fraudulent transactions as fraudulent.\n",
    "\n",
    "It is highly probable that while focusing on correctly identifying the class of interest (fraudulent transactions) i.e. the TPs, the model makes some mistakes i.e. FPs (marking non-fraudulent transactions as fraudulent). Thus it’s important to look at a measure that compares TPR and FPR. This is where AUC fits in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
